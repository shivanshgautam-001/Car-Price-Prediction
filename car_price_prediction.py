# -*- coding: utf-8 -*-
"""Car Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_XJihU_3D3EjDFOs8oOp-48CwViL8Lfw

# **To predict the car price**
"""

from google.colab import files
uploaded = files.upload()

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv('CarPrice_Assignment.csv')

df.shape

df.head()

df.info()

df.columns

df.describe()

df.isnull().sum()

price_counts=df['price'].value_counts()
price_counts

plt.figure(figsize=(250,20))
plot=sns.countplot(data=df, x='price')
plt.title('Count of Price')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(10, 6))
plt.hist(df['price'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of Car Prices')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
plt.boxplot(df['price'], vert=False)
plt.title('Box Plot of Car Prices')
plt.xlabel('Price')
plt.grid(True)
plt.show()

carname_counts=df['CarName'].value_counts()
print(carname_counts)

for car_name, count in carname_counts.items():
    print(f'{car_name}: {count}')

df['CarName'].value_counts().sum()

plt.figure(figsize=(250,20))
plot=sns.countplot(data=df, x='CarName')
plt.title('Count of CarName')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(200, 20),dpi=99)
plt.hist(df['CarName'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of Car Name')
plt.xlabel('Car Name')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10,5))
plot=sns.countplot(data=df, x='fueltype')
plt.title('Count of Fuel Type')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(10,5))
plot=sns.countplot(data=df, x='enginelocation')
plt.title('Count of Engine Location')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(10,5))
plot=sns.countplot(data=df, x='enginetype')
plt.title('Count of Engine Type')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(20,5))
plot=sns.countplot(data=df, x='stroke')
plt.title('Count of Stroke')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(20,5))
plot=sns.countplot(data=df, x='compressionratio')
plt.title('Count of compressionratio')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(25,5))
plot=sns.countplot(data=df, x='horsepower')
plt.title('Count of horsepower')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(20,5))
plot=sns.countplot(data=df, x='citympg')
plt.title('Count of citympg')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

plt.figure(figsize=(20,5))
plot=sns.countplot(data=df, x='highwaympg')
plt.title('Count of highwaympg')
plt.xticks()
# Display count values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.0f'),
                  (p.get_x() + p.get_width() / 2., p.get_height()),
                  ha = 'center', va = 'center',
                  xytext = (0, 10),
                  textcoords = 'offset points')

plt.show()

sns.pairplot(df, hue='price', palette='bright',diag_kind='kde')
plt.legend(df)
plt.show()

numeric_features = df.select_dtypes(include=['number'])
print("Numeric Features:")
print(numeric_features.columns)

numeric_features = ['car_ID', 'symboling', 'wheelbase', 'carlength',
                    'carwidth','carheight', 'curbweight', 'enginesize',
                    'boreratio', 'stroke','compressionratio', 'horsepower',
                    'peakrpm', 'citympg', 'highwaympg','price']

for column in df.columns:
    if column != 'price':
        plt.figure(figsize=(10, 5))
        sns.histplot(df[column], bins='sturges', alpha=0.5, label=column)
        sns.histplot(df['price'], bins='sturges', alpha=0.5, label='price')
        plt.xlabel(column)
        plt.ylabel('Frequency')
        plt.title(f'Histogram of {column} with Comparison to Price')
        plt.legend()
        plt.show()

plt.figure(figsize=(20, 5))
sns.boxplot(data=df.drop(columns='price'))
plt.title('Boxplot for Columns with Comparison to Price')
plt.ylabel('Value')
plt.show()

# Exclude non-numeric columns
numeric_df = df.select_dtypes(include=['number'])

# Calculate the correlation matrix
correlation_matrix = numeric_df.corr()

# Display the correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

df.hist(figsize=(12, 10))
plt.suptitle('Histograms for Dataset Columns', x=0.5, y=1.02)
plt.show()

for column in df.columns:
    if column != 'price' and not pd.api.types.is_numeric_dtype(df[column]):
        df[column] = pd.to_numeric(df[column], errors='coerce')
for column in df.columns:
    if column != 'price':
        plt.figure(figsize=(10, 6))
        sns.regplot(x=column, y='price', data=df, scatter_kws={'alpha':0.5})
        plt.xlabel(column)
        plt.ylabel('Price')
        plt.title(f'Regression Plot for {column} against Price')
        plt.show()

# Split data into features and target variable
X = df.drop(columns=['price'])
y = df['price']

# Replace NaN values with the mean of each column
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)

# Scale the input features
sc_X = StandardScaler()
X_train_scaled = sc_X.fit_transform(X_train)
X_test_scaled = sc_X.transform(X_test)

# Initialize lists to store the results
models = []
model_names = []
train_scores = []
test_scores = []

# Function to train and evaluate the model
def train_and_evaluate(model, model_name):
    # Train the model
    model.fit(X_train_scaled, y_train.ravel())

    # Calculate training accuracy
    train_score = model.score(X_train_scaled, y_train)

    # Calculate testing accuracy
    test_score = model.score(X_test_scaled, y_test)

    # Append the results
    models.append(model)
    model_names.append(model_name)
    train_scores.append(train_score)
    test_scores.append(test_score)

# Linear Regression
train_and_evaluate(LinearRegression(), "Linear Regression")

# Decision Tree Regressor
train_and_evaluate(DecisionTreeRegressor(random_state=42), "Decision Tree Regressor")

# Random Forest Regressor
train_and_evaluate(RandomForestRegressor(n_estimators=100, random_state=42), "Random Forest Regressor")

# Gradient Boosting Regressor
train_and_evaluate(GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42), "Gradient Boosting Regressor")

# Support Vector Regressor
train_and_evaluate(SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1), "Support Vector Regressor")

# Voting Regressor
voting_regressor = VotingRegressor([('lr', LinearRegression()), ('dt', DecisionTreeRegressor(random_state=42)),
                                    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),
                                    ('gb', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),
                                    ('svr', SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1))])
train_and_evaluate(voting_regressor, "Voting Regressor")

# Create a DataFrame to store the results
results_df = pd.DataFrame({
    "S.no": range(1, len(model_names) + 1),
    "ML Algorithm": model_names,
    "Training Accuracy": train_scores,
    "Testing Accuracy": test_scores
})

# Display the results
print(results_df)

# Predict prices for each model
y_pred_lr = models[0].predict(X_test_scaled)
y_pred_dt = models[1].predict(X_test_scaled)
y_pred_rf = models[2].predict(X_test_scaled)
y_pred_gb = models[3].predict(X_test_scaled)
y_pred_svr = models[4].predict(X_test_scaled)
y_pred_vr = models[5].predict(X_test_scaled)

# Create DataFrame to store predicted prices
pred_results_df = pd.DataFrame({
    "ID": range(1, len(X_test) + 1),
    "Actual Price": y_test.ravel(),
    "Linear Regression": y_pred_lr.ravel(),
    "Decision Tree Regressor": y_pred_dt.ravel(),
    "Random Forest Regressor": y_pred_rf.ravel(),
    "Gradient Boosting Regressor": y_pred_gb.ravel(),
    "Support Vector Regressor": y_pred_svr.ravel(),
    "Voting Regressor": y_pred_vr.ravel()
})

# Display the DataFrame with predicted prices
print(pred_results_df)

